{
  "title": "Risk To Humanity",
  "story": [
    {
      "type": "paragraph",
      "id": "32a6423071c9af73",
      "text": "The following is taken from Lynn M. LoPucki [[Algorithmic Entities]] - [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2954173 papers.ssrn.com]"
    },
    {
      "type": "pagefold",
      "id": "0e52f5677ff9b629",
      "text": "The Threat from Algorithm Plus Entity"
    },
    {
      "type": "paragraph",
      "id": "d68a0de09fe6933b",
      "text": "To the contrary, the risk to humanity from AEs is greater than the risk from algorithms with human collaborators for at least three reasons. Entities\nwithout human collaborators could be more ruthless, more difficult to deter, and easier to replicate - [https://poseidon01.ssrn.com/delivery.php?ID=757114096124124124086089001010095023030092050084043069014030074120089118098115064110018011103047026000040100119122088006126117045037034011050080083094065100089075089043020082071113072006012106017113086069125028089029110111123005071075074002125124001&EXT=pdf pdf]"
    },
    {
      "type": "markdown",
      "id": "a438bd5d06feffaf",
      "text": "# Ruthlessness"
    },
    {
      "type": "paragraph",
      "id": "1bfb0468bd649fb7",
      "text": "Unless explicitly or implicitly programmed to have them, AEs will lack sympathy and empathy. Even if the AEs are fully capable of understanding\nthe effects of their actions on humans, they may be indifferent to those effects. As a result, AEs will have a wider range of options available to them than would be available to even the most morally lax human controller. "
    },
    {
      "type": "paragraph",
      "id": "c054a3ad9618cfb9",
      "text": "An AE could pursue its goals with utter ruthlessness. Virtually any human controller would stop somewhere short of that, making the AE more dangerous.\n"
    },
    {
      "type": "markdown",
      "id": "8c98643baae54640",
      "text": "# Lack of Deterrability"
    },
    {
      "type": "paragraph",
      "id": "18ce12ae4ee16f6a",
      "text": "Outsiders can more easily deter a human-controlled entity than an AE. For example, if a human-controlled entity attempts to pursue an illegal course of action, the government can threaten to incarcerate the human controller. If the course of action is merely abhorrent, colleagues, friends, and relatives could apply social pressures. AEs lack those vulnerabilities\nbecause no human associated with them has control. "
    },
    {
      "type": "paragraph",
      "id": "acf44c4bbc85c06c",
      "text": "As a result, AEs have greater freedom to pursue unpopular goals using unpopular methods.\nIn deciding to attempt a coup, bomb a restaurant, or assemble an armed group to attack a shopping center, a human-controlled entity puts the lives\nof its human controllers at risk. The same decisions on behalf of an AE risk nothing but the resources the AE spends in planning and execution. If an\nAE cares at all about self-preservation, it will be only as a means of achieving some other goal for which it has been programmed."
    },
    {
      "type": "paragraph",
      "id": "7983e62fd011eb71",
      "text": "Deterrence of an AE from its goals, as distinguished from particular means of achieving them, is impossible.\n\n"
    },
    {
      "type": "markdown",
      "id": "931944a411f9d39e",
      "text": "# Replication"
    },
    {
      "type": "paragraph",
      "id": "54e51164840c5e19",
      "text": "AEs can replicate themselves quickly and easily. If an AE’s operations are entirely online, replication may be as easy as forming a new entity and\nelectronically copying an algorithm. An entity can be formed in some jurisdictions in as little as an hour and for as little as seventy dollars."
    },
    {
      "type": "paragraph",
      "id": "926e00876daec803",
      "text": "While entities are not, strictly speaking, copies of other entities, they can\nbe identical to other entities, which has the same effect."
    },
    {
      "type": "paragraph",
      "id": "fa872e0ad9b7f282",
      "text": "Easy replication supports several possible strategies. First, replication in a destination jurisdiction followed by dissolution of the entity in the original\njurisdiction may put the AE beyond the legal reach of the original jurisdiction."
    },
    {
      "type": "paragraph",
      "id": "d71cca1a76ccef30",
      "text": "For a human-controlled entity to escape the reach of the original jurisdiction, the human would have to move physically to the destination jurisdiction.\n"
    },
    {
      "type": "paragraph",
      "id": "cf6d1a33bb8bb3e3",
      "text": "Second, replication can make an AE harder to destroy. For example, if copies of an AE exist in three jurisdictions, each is a person with its own\nrights. A court order revoking the charter of one or seizing the assets of another would have no effect on the third."
    },
    {
      "type": "paragraph",
      "id": "a58808ab5221c5ed",
      "text": "It could continue to exist and replicate further. The strategy does not work as well for a human-controlled entity. To replicate a human-controlled entity, one must either recruit additional humans to control the copies or put the same human in control of the copies. The former is time consuming because it requires a personnel search. It is complex because each human must be appropriately motivated.\n"
    },
    {
      "type": "paragraph",
      "id": "6af03c41eee13078",
      "text": "It is risky because every person is different and difficult to assess. The latter leaves the same person in control of all the entities, providing the basis for\na court to disregard their separate existences. In short, algorithms can be almost instantly cloned; humans cannot."
    },
    {
      "type": "paragraph",
      "id": "3b4f3e89e1b8a871",
      "text": "Third, replication can operate as a method of hedging. Consider, for example, the hypothetical situation in which ten jurisdictions are\nconsidering a ban on AEs and the ban has a ninety percent chance of adoption in each. An AE that replicated itself in each of the ten jurisdictions\nwould expect to survive in one."
    },
    {
      "type": "paragraph",
      "id": "23c740208cf6fea8",
      "text": "Fourth, because they know what each other will do, replications may be able to cooperate for mutual benefit without the necessity for agreement\nor collusion. Ants and bees are biological examples of organisms in which replications cooperate."
    },
    {
      "type": "pagefold",
      "id": "a4380be681a76e37",
      "text": "."
    },
    {
      "type": "paragraph",
      "id": "9e3680602fce32a5",
      "text": "This Part argues that current law provides no effective mechanisms for\npreventing the formation of algorithmic entities or controlling them once\nthey exist. First, initiators could put algorithms in control of most types of\nartificial entities without violating any law. As the entity system currently\noperates, initiators—and AEs once they are formed—can choose among\nthousands of entity types made available by hundreds of states and\ncountries. Second, if threatened by proposed changes in their governing\nlegal regimes, algorithms could change legal regimes by migrating across\nborders or changing entity types. They could do so without changing the\nlocations of their physical operations. Third, in most jurisdictions, the law\ndoes not require that entities reveal their beneficial owners or controllers,\nmaking it difficult, if not impossible, for enforcement agencies to identify\nthose whose controllers are not human. Each of these three points is\naddressed in a separate section"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Risk To Humanity",
        "story": []
      },
      "date": 1519632270477
    },
    {
      "item": {
        "type": "factory",
        "id": "32a6423071c9af73"
      },
      "id": "32a6423071c9af73",
      "type": "add",
      "date": 1519632271354
    },
    {
      "type": "edit",
      "id": "32a6423071c9af73",
      "item": {
        "type": "paragraph",
        "id": "32a6423071c9af73",
        "text": "To the contrary, the risk to humanity from AEs is greater than the risk\nfrom algorithms with human collaborators for at least three reasons. Entities\nwithout human collaborators could be more ruthless, more difficult to deter,\nand easier to replicate.\na. Ruthlessness\nUnless explicitly or implicitly programmed to have them, AEs will lack\nsympathy and empathy. Even if the AEs are fully capable of understanding\nthe effects of their actions on humans, they may be indifferent to those\neffects. As a result, AEs will have a wider range of options available to them\nthan would be available to even the most morally lax human controller. An\nAE could pursue its goals with utter ruthlessness. Virtually any human\ncontroller would stop somewhere short of that, making the AE more\ndangerous.\nb. Lack of Deterrability\nOutsiders can more easily deter a human-controlled entity than an AE.\nFor example, if a human-controlled entity attempts to pursue an illegal\ncourse of action, the government can threaten to incarcerate the human\ncontroller. If the course of action is merely abhorrent, colleagues, friends,\nand relatives could apply social pressures. AEs lack those vulnerabilities\nbecause no human associated with them has control. As a result, AEs have\ngreater freedom to pursue unpopular goals using unpopular methods.\nIn deciding to attempt a coup, bomb a restaurant, or assemble an armed\ngroup to attack a shopping center, a human-controlled entity puts the lives\nof its human controllers at risk. The same decisions on behalf of an AE risk\nnothing but the resources the AE spends in planning and execution. If an\nAE cares at all about self-preservation, it will be only as a means of\nachieving some other goal for which it has been programmed.88 Deterrence\nof an AE from its goals, as distinguished from particular means of achieving\nthem, is impossible.\n88. See, e.g., MURRAY SHANAHAN, THE TECHNOLOGICAL SINGULARITY 145–46 (2015); id. at 146\n(“[I]f the AI’s reward function involves maximizing widget production, then the optimal strategy might\nbe to commission a widget factor and then self-destruct.”); Ben Goertzel, Superintelligence: Fears,\nPromises and Potentials, 24 J. EVOLUTION & TECH. 55 (2015) (“It may well be that “self-preservation”\nis an anthropomorphic or biomorphic idea, and very advanced AGI systems might go far beyond such\nnotions.”). \n2018] ALGORITHMIC ENTITIES 19\nc. Replication\nAEs can replicate themselves quickly and easily. If an AE’s operations\nare entirely online, replication may be as easy as forming a new entity and\nelectronically copying an algorithm. An entity can be formed in some\njurisdictions in as little as an hour and for as little as seventy dollars.89\n(While entities are not, strictly speaking, copies of other entities, they can\nbe identical to other entities, which has the same effect.)\nEasy replication supports several possible strategies. First, replication in\na destination jurisdiction followed by dissolution of the entity in the original\njurisdiction may put the AE beyond the legal reach of the original\njurisdiction.90 For a human-controlled entity to escape the reach of the\noriginal jurisdiction, the human would have to move physically to the\ndestination jurisdiction.\n Second, replication can make an AE harder to destroy. For example, if\ncopies of an AE exist in three jurisdictions, each is a person with its own\nrights. A court order revoking the charter of one or seizing the assets of\nanother would have no effect on the third. It could continue to exist and\nreplicate further. The strategy does not work as well for a human-controlled\nentity. To replicate a human-controlled entity, one must either recruit\nadditional humans to control the copies or put the same human in control of\nthe copies. The former is time consuming because it requires a personnel\nsearch. It is complex because each human must be appropriately motivated.\nIt is risky because every person is different and difficult to assess. The latter\nleaves the same person in control of all the entities, providing the basis for\na court to disregard their separate existences. In short, algorithms can be\nalmost instantly cloned; humans cannot.\nThird, replication can operate as a method of hedging. Consider, for\nexample, the hypothetical situation in which ten jurisdictions are\nconsidering a ban on AEs and the ban has a ninety percent chance of\nadoption in each. An AE that replicated itself in each of the ten jurisdictions\nwould expect to survive in one.\nFourth, because they know what each other will do,91 replications may\n89. Arizona Corporation Commission, Corporations Division Fee Schedule – Limited Liability\nCompanies, http://www.azcc.gov/Divisions/Corporations/Fee-Schedule-LLCs.pdf (showing “total fee\nfor regular processing” as $50 for LLC Articles of Organization); State of Delaware: The Official\nWebsite of the First State, https://corp.delaware.gov/expserv.shtml (offering one-hour incorporation for\n$1,000).\n90. This strategy is the subject of Part II.B below.\n91. By definition, each replication contains the same code. A replication can predict the actions of\nanother by examining its own code. \n20 WASHINGTON UNIVERSITY LAW REVIEW [VOL. 95:1\nbe able to cooperate for mutual benefit without the necessity for agreement\nor collusion. Ants and bees are biological examples of organisms in which\nreplications cooperate."
      },
      "date": 1519632276149
    },
    {
      "type": "edit",
      "id": "32a6423071c9af73",
      "item": {
        "type": "paragraph",
        "id": "32a6423071c9af73",
        "text": "To the contrary, the risk to humanity from AEs is greater than the risk from algorithms with human collaborators for at least three reasons. Entities\nwithout human collaborators could be more ruthless, more difficult to deter, and easier to replicate."
      },
      "date": 1519632296671
    },
    {
      "type": "add",
      "id": "a438bd5d06feffaf",
      "item": {
        "type": "paragraph",
        "id": "a438bd5d06feffaf",
        "text": "# Ruthlessness"
      },
      "after": "32a6423071c9af73",
      "date": 1519632302879
    },
    {
      "type": "add",
      "id": "1bfb0468bd649fb7",
      "item": {
        "type": "paragraph",
        "id": "1bfb0468bd649fb7",
        "text": "Unless explicitly or implicitly programmed to have them, AEs will lack sympathy and empathy. Even if the AEs are fully capable of understanding\nthe effects of their actions on humans, they may be indifferent to those\neffects. As a result, AEs will have a wider range of options available to them\nthan would be available to even the most morally lax human controller. An\nAE could pursue its goals with utter ruthlessness. Virtually any human\ncontroller would stop somewhere short of that, making the AE more\ndangerous.\nb. Lack of Deterrability\nOutsiders can more easily deter a human-controlled entity than an AE.\nFor example, if a human-controlled entity attempts to pursue an illegal\ncourse of action, the government can threaten to incarcerate the human\ncontroller. If the course of action is merely abhorrent, colleagues, friends,\nand relatives could apply social pressures. AEs lack those vulnerabilities\nbecause no human associated with them has control. As a result, AEs have\ngreater freedom to pursue unpopular goals using unpopular methods.\nIn deciding to attempt a coup, bomb a restaurant, or assemble an armed\ngroup to attack a shopping center, a human-controlled entity puts the lives\nof its human controllers at risk. The same decisions on behalf of an AE risk\nnothing but the resources the AE spends in planning and execution. If an\nAE cares at all about self-preservation, it will be only as a means of\nachieving some other goal for which it has been programmed.88 Deterrence\nof an AE from its goals, as distinguished from particular means of achieving\nthem, is impossible.\n88. See, e.g., MURRAY SHANAHAN, THE TECHNOLOGICAL SINGULARITY 145–46 (2015); id. at 146\n(“[I]f the AI’s reward function involves maximizing widget production, then the optimal strategy might\nbe to commission a widget factor and then self-destruct.”); Ben Goertzel, Superintelligence: Fears,\nPromises and Potentials, 24 J. EVOLUTION & TECH. 55 (2015) (“It may well be that “self-preservation”\nis an anthropomorphic or biomorphic idea, and very advanced AGI systems might go far beyond such\nnotions.”). \n2018] ALGORITHMIC ENTITIES 19\nc. Replication\nAEs can replicate themselves quickly and easily. If an AE’s operations\nare entirely online, replication may be as easy as forming a new entity and\nelectronically copying an algorithm. An entity can be formed in some\njurisdictions in as little as an hour and for as little as seventy dollars.89\n(While entities are not, strictly speaking, copies of other entities, they can\nbe identical to other entities, which has the same effect.)\nEasy replication supports several possible strategies. First, replication in\na destination jurisdiction followed by dissolution of the entity in the original\njurisdiction may put the AE beyond the legal reach of the original\njurisdiction.90 For a human-controlled entity to escape the reach of the\noriginal jurisdiction, the human would have to move physically to the\ndestination jurisdiction.\n Second, replication can make an AE harder to destroy. For example, if\ncopies of an AE exist in three jurisdictions, each is a person with its own\nrights. A court order revoking the charter of one or seizing the assets of\nanother would have no effect on the third. It could continue to exist and\nreplicate further. The strategy does not work as well for a human-controlled\nentity. To replicate a human-controlled entity, one must either recruit\nadditional humans to control the copies or put the same human in control of\nthe copies. The former is time consuming because it requires a personnel\nsearch. It is complex because each human must be appropriately motivated.\nIt is risky because every person is different and difficult to assess. The latter\nleaves the same person in control of all the entities, providing the basis for\na court to disregard their separate existences. In short, algorithms can be\nalmost instantly cloned; humans cannot.\nThird, replication can operate as a method of hedging. Consider, for\nexample, the hypothetical situation in which ten jurisdictions are\nconsidering a ban on AEs and the ban has a ninety percent chance of\nadoption in each. An AE that replicated itself in each of the ten jurisdictions\nwould expect to survive in one.\nFourth, because they know what each other will do,91 replications may\n89. Arizona Corporation Commission, Corporations Division Fee Schedule – Limited Liability\nCompanies, http://www.azcc.gov/Divisions/Corporations/Fee-Schedule-LLCs.pdf (showing “total fee\nfor regular processing” as $50 for LLC Articles of Organization); State of Delaware: The Official\nWebsite of the First State, https://corp.delaware.gov/expserv.shtml (offering one-hour incorporation for\n$1,000).\n90. This strategy is the subject of Part II.B below.\n91. By definition, each replication contains the same code. A replication can predict the actions of\nanother by examining its own code. \n20 WASHINGTON UNIVERSITY LAW REVIEW [VOL. 95:1\nbe able to cooperate for mutual benefit without the necessity for agreement\nor collusion. Ants and bees are biological examples of organisms in which\nreplications cooperate."
      },
      "after": "a438bd5d06feffaf",
      "date": 1519632306881
    },
    {
      "type": "edit",
      "id": "32a6423071c9af73",
      "item": {
        "type": "paragraph",
        "id": "32a6423071c9af73",
        "text": "To the contrary, the risk to humanity from AEs is greater than the risk from algorithms with human collaborators for at least three reasons. Entities\nwithout human collaborators could be more ruthless, more difficult to deter, and easier to replicate - [https://poseidon01.ssrn.com/delivery.php?ID=757114096124124124086089001010095023030092050084043069014030074120089118098115064110018011103047026000040100119122088006126117045037034011050080083094065100089075089043020082071113072006012106017113086069125028089029110111123005071075074002125124001&EXT=pdf pdf]"
      },
      "date": 1519632313178
    },
    {
      "type": "edit",
      "id": "a438bd5d06feffaf",
      "item": {
        "type": "markdown",
        "id": "a438bd5d06feffaf",
        "text": "# Ruthlessness"
      },
      "date": 1519632316161
    },
    {
      "type": "edit",
      "id": "1bfb0468bd649fb7",
      "item": {
        "type": "paragraph",
        "id": "1bfb0468bd649fb7",
        "text": "Unless explicitly or implicitly programmed to have them, AEs will lack sympathy and empathy. Even if the AEs are fully capable of understanding\nthe effects of their actions on humans, they may be indifferent to those effects. As a result, AEs will have a wider range of options available to them than would be available to even the most morally lax human controller. "
      },
      "date": 1519632339103
    },
    {
      "type": "add",
      "id": "c054a3ad9618cfb9",
      "item": {
        "type": "paragraph",
        "id": "c054a3ad9618cfb9",
        "text": "An AE could pursue its goals with utter ruthlessness. Virtually any human controller would stop somewhere short of that, making the AE more dangerous.\n"
      },
      "after": "1bfb0468bd649fb7",
      "date": 1519632354482
    },
    {
      "type": "add",
      "id": "8c98643baae54640",
      "item": {
        "type": "paragraph",
        "id": "8c98643baae54640",
        "text": "# Lack of Deterrability"
      },
      "after": "c054a3ad9618cfb9",
      "date": 1519632358008
    },
    {
      "type": "add",
      "id": "18ce12ae4ee16f6a",
      "item": {
        "type": "paragraph",
        "id": "18ce12ae4ee16f6a",
        "text": "Outsiders can more easily deter a human-controlled entity than an AE. For example, if a human-controlled entity attempts to pursue an illegal course of action, the government can threaten to incarcerate the human controller. If the course of action is merely abhorrent, colleagues, friends, and relatives could apply social pressures. AEs lack those vulnerabilities\nbecause no human associated with them has control. "
      },
      "after": "8c98643baae54640",
      "date": 1519632374336
    },
    {
      "type": "edit",
      "id": "8c98643baae54640",
      "item": {
        "type": "markdown",
        "id": "8c98643baae54640",
        "text": "# Lack of Deterrability"
      },
      "date": 1519632376257
    },
    {
      "type": "add",
      "id": "acf44c4bbc85c06c",
      "item": {
        "type": "paragraph",
        "id": "acf44c4bbc85c06c",
        "text": "As a result, AEs have greater freedom to pursue unpopular goals using unpopular methods.\nIn deciding to attempt a coup, bomb a restaurant, or assemble an armed group to attack a shopping center, a human-controlled entity puts the lives\nof its human controllers at risk. The same decisions on behalf of an AE risk nothing but the resources the AE spends in planning and execution. If an\nAE cares at all about self-preservation, it will be only as a means of achieving some other goal for which it has been programmed."
      },
      "after": "18ce12ae4ee16f6a",
      "date": 1519632407450
    },
    {
      "type": "add",
      "id": "7983e62fd011eb71",
      "item": {
        "type": "paragraph",
        "id": "7983e62fd011eb71",
        "text": "Deterrence of an AE from its goals, as distinguished from particular means of achieving them, is impossible.\n\n"
      },
      "after": "acf44c4bbc85c06c",
      "date": 1519632452066
    },
    {
      "type": "add",
      "id": "931944a411f9d39e",
      "item": {
        "type": "paragraph",
        "id": "931944a411f9d39e",
        "text": "# Replication"
      },
      "after": "7983e62fd011eb71",
      "date": 1519632454940
    },
    {
      "type": "edit",
      "id": "931944a411f9d39e",
      "item": {
        "type": "markdown",
        "id": "931944a411f9d39e",
        "text": "# Replication"
      },
      "date": 1519632458137
    },
    {
      "type": "add",
      "id": "54e51164840c5e19",
      "item": {
        "type": "paragraph",
        "id": "54e51164840c5e19",
        "text": "AEs can replicate themselves quickly and easily. If an AE’s operations are entirely online, replication may be as easy as forming a new entity and\nelectronically copying an algorithm. An entity can be formed in some jurisdictions in as little as an hour and for as little as seventy dollars."
      },
      "after": "931944a411f9d39e",
      "date": 1519632494684
    },
    {
      "type": "add",
      "id": "926e00876daec803",
      "item": {
        "type": "paragraph",
        "id": "926e00876daec803",
        "text": "While entities are not, strictly speaking, copies of other entities, they can\nbe identical to other entities, which has the same effect."
      },
      "after": "54e51164840c5e19",
      "date": 1519632497960
    },
    {
      "type": "add",
      "id": "fa872e0ad9b7f282",
      "item": {
        "type": "paragraph",
        "id": "fa872e0ad9b7f282",
        "text": "Easy replication supports several possible strategies. First, replication in a destination jurisdiction followed by dissolution of the entity in the original\njurisdiction may put the AE beyond the legal reach of the original jurisdiction."
      },
      "after": "926e00876daec803",
      "date": 1519632513844
    },
    {
      "type": "add",
      "id": "d71cca1a76ccef30",
      "item": {
        "type": "paragraph",
        "id": "d71cca1a76ccef30",
        "text": "For a human-controlled entity to escape the reach of the original jurisdiction, the human would have to move physically to the destination jurisdiction.\n"
      },
      "after": "fa872e0ad9b7f282",
      "date": 1519632521110
    },
    {
      "type": "add",
      "id": "cf6d1a33bb8bb3e3",
      "item": {
        "type": "paragraph",
        "id": "cf6d1a33bb8bb3e3",
        "text": "Second, replication can make an AE harder to destroy. For example, if copies of an AE exist in three jurisdictions, each is a person with its own\nrights. A court order revoking the charter of one or seizing the assets of another would have no effect on the third."
      },
      "after": "d71cca1a76ccef30",
      "date": 1519632534089
    },
    {
      "type": "add",
      "id": "a58808ab5221c5ed",
      "item": {
        "type": "paragraph",
        "id": "a58808ab5221c5ed",
        "text": "It could continue to exist and replicate further. The strategy does not work as well for a human-controlled entity. To replicate a human-controlled entity, one must either recruit additional humans to control the copies or put the same human in control of the copies. The former is time consuming because it requires a personnel search. It is complex because each human must be appropriately motivated.\n"
      },
      "after": "cf6d1a33bb8bb3e3",
      "date": 1519632554747
    },
    {
      "type": "add",
      "id": "6af03c41eee13078",
      "item": {
        "type": "paragraph",
        "id": "6af03c41eee13078",
        "text": "It is risky because every person is different and difficult to assess. The latter leaves the same person in control of all the entities, providing the basis for\na court to disregard their separate existences. In short, algorithms can be almost instantly cloned; humans cannot."
      },
      "after": "a58808ab5221c5ed",
      "date": 1519632563499
    },
    {
      "type": "add",
      "id": "3b4f3e89e1b8a871",
      "item": {
        "type": "paragraph",
        "id": "3b4f3e89e1b8a871",
        "text": "Third, replication can operate as a method of hedging. Consider, for example, the hypothetical situation in which ten jurisdictions are\nconsidering a ban on AEs and the ban has a ninety percent chance of adoption in each. An AE that replicated itself in each of the ten jurisdictions\nwould expect to survive in one."
      },
      "after": "6af03c41eee13078",
      "date": 1519632575402
    },
    {
      "type": "add",
      "id": "23c740208cf6fea8",
      "item": {
        "type": "paragraph",
        "id": "23c740208cf6fea8",
        "text": "Fourth, because they know what each other will do, replications may. Arizona Corporation Commission, Corporations Division Fee Schedule – Limited Liability\nCompanies, http://www.azcc.gov/Divisions/Corporations/Fee-Schedule-LLCs.pdf (showing “total fee\nfor regular processing” as $50 for LLC Articles of Organization); State of Delaware: The Official\nWebsite of the First State, https://corp.delaware.gov/expserv.shtml (offering one-hour incorporation for\n$1,000).\n90. This strategy is the subject of Part II.B below.\n91. By definition, each replication contains the same code. A replication can predict the actions of\nanother by examining its own code. \n20 WASHINGTON UNIVERSITY LAW REVIEW [VOL. 95:1\nbe able to cooperate for mutual benefit without the necessity for agreement\nor collusion. Ants and bees are biological examples of organisms in which\nreplications cooperate."
      },
      "after": "3b4f3e89e1b8a871",
      "date": 1519632601019
    },
    {
      "type": "edit",
      "id": "23c740208cf6fea8",
      "item": {
        "type": "paragraph",
        "id": "23c740208cf6fea8",
        "text": "Fourth, because they know what each other will do, replications may be able to cooperate for mutual benefit without the necessity for agreement\nor collusion. Ants and bees are biological examples of organisms in which replications cooperate."
      },
      "date": 1519632636566
    },
    {
      "type": "edit",
      "id": "32a6423071c9af73",
      "item": {
        "type": "paragraph",
        "id": "32a6423071c9af73",
        "text": "The following is taken from Lynn M. LoPucki"
      },
      "date": 1519632685835
    },
    {
      "type": "add",
      "id": "d68a0de09fe6933b",
      "item": {
        "type": "paragraph",
        "id": "d68a0de09fe6933b",
        "text": "To the contrary, the risk to humanity from AEs is greater than the risk from algorithms with human collaborators for at least three reasons. Entities\nwithout human collaborators could be more ruthless, more difficult to deter, and easier to replicate - [https://poseidon01.ssrn.com/delivery.php?ID=757114096124124124086089001010095023030092050084043069014030074120089118098115064110018011103047026000040100119122088006126117045037034011050080083094065100089075089043020082071113072006012106017113086069125028089029110111123005071075074002125124001&EXT=pdf pdf]"
      },
      "after": "32a6423071c9af73",
      "date": 1519632690043
    },
    {
      "type": "edit",
      "id": "32a6423071c9af73",
      "item": {
        "type": "paragraph",
        "id": "32a6423071c9af73",
        "text": "The following is taken from Lynn M. LoPucki [[Algorithmic Entities]] "
      },
      "date": 1519632701488
    },
    {
      "type": "edit",
      "id": "32a6423071c9af73",
      "item": {
        "type": "paragraph",
        "id": "32a6423071c9af73",
        "text": "The following is taken from Lynn M. LoPucki [[Algorithmic Entities]] - [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2954173 papers.ssrn.com]"
      },
      "date": 1519632714023
    },
    {
      "item": {
        "type": "factory",
        "id": "a4380be681a76e37"
      },
      "id": "a4380be681a76e37",
      "type": "add",
      "after": "23c740208cf6fea8",
      "date": 1519632717727
    },
    {
      "type": "edit",
      "id": "a4380be681a76e37",
      "item": {
        "type": "pagefold",
        "id": "a4380be681a76e37",
        "text": "."
      },
      "date": 1519632720806
    },
    {
      "item": {
        "type": "factory",
        "id": "0e52f5677ff9b629"
      },
      "id": "0e52f5677ff9b629",
      "type": "add",
      "after": "a4380be681a76e37",
      "date": 1519632722085
    },
    {
      "type": "move",
      "order": [
        "32a6423071c9af73",
        "0e52f5677ff9b629",
        "d68a0de09fe6933b",
        "a438bd5d06feffaf",
        "1bfb0468bd649fb7",
        "c054a3ad9618cfb9",
        "8c98643baae54640",
        "18ce12ae4ee16f6a",
        "acf44c4bbc85c06c",
        "7983e62fd011eb71",
        "931944a411f9d39e",
        "54e51164840c5e19",
        "926e00876daec803",
        "fa872e0ad9b7f282",
        "d71cca1a76ccef30",
        "cf6d1a33bb8bb3e3",
        "a58808ab5221c5ed",
        "6af03c41eee13078",
        "3b4f3e89e1b8a871",
        "23c740208cf6fea8",
        "a4380be681a76e37"
      ],
      "id": "0e52f5677ff9b629",
      "date": 1519632729231
    },
    {
      "type": "edit",
      "id": "0e52f5677ff9b629",
      "item": {
        "type": "pagefold",
        "id": "0e52f5677ff9b629",
        "text": "The Threat from Algorithm Plus Entity"
      },
      "date": 1519632770119
    },
    {
      "item": {
        "type": "factory",
        "id": "9e3680602fce32a5"
      },
      "id": "9e3680602fce32a5",
      "type": "add",
      "after": "a4380be681a76e37",
      "date": 1519632829858
    },
    {
      "type": "edit",
      "id": "9e3680602fce32a5",
      "item": {
        "type": "paragraph",
        "id": "9e3680602fce32a5",
        "text": "This Part argues that current law provides no effective mechanisms for\npreventing the formation of algorithmic entities or controlling them once\nthey exist. First, initiators could put algorithms in control of most types of\nartificial entities without violating any law. As the entity system currently\noperates, initiators—and AEs once they are formed—can choose among\nthousands of entity types made available by hundreds of states and\ncountries. Second, if threatened by proposed changes in their governing\nlegal regimes, algorithms could change legal regimes by migrating across\nborders or changing entity types. They could do so without changing the\nlocations of their physical operations. Third, in most jurisdictions, the law\ndoes not require that entities reveal their beneficial owners or controllers,\nmaking it difficult, if not impossible, for enforcement agencies to identify\nthose whose controllers are not human. Each of these three points is\naddressed in a separate section"
      },
      "date": 1519632833639
    }
  ]
}