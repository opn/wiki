{
  "title": "AI Safety",
  "story": [
    {
      "type": "markdown",
      "id": "c5aaeabfc6ea0fd6",
      "text": "AI Safety is, crudely, the concern that a true Artificial General Intelligence - one with an equivalent intelligence to a human, but with the additional technical nature of a machine (in other words, lacking the restrictions imposed by consisting of an organic 'whole'), could become superhuman in capacity, and that in this situation, it would be of critical importance that it be reliably 'friendly' to humans, and sufficiently aligned with human values that it would not make judgements about what it should do which would not be prejudicial to humans."
    },
    {
      "type": "markdown",
      "id": "2b56ac3fad49737f",
      "text": "This concern breaks down into a number of sub-topics:\n- the [[AI Alignment Problem]]\n- approaches to building [[Non-Superhuman AGI]] \n- approaches to building [[disinterested AGI]]"
    },
    {
      "type": "markdown",
      "id": "e19c4c7e8c1919de",
      "text": "LINKS\n- [Friendly AI through Ontology auto generation](https://medium.com/@pwgen/friendly-ai-through-ontology-autogeneration-5d375bf85922)\n- [Lesser Wrong AI Alignment prize](https://www.lesserwrong.com/posts/4WbNGQMvuFtY3So7s/announcement-ai-alignment-prize-winners-and-next-round)"
    },
    {
      "type": "markdown",
      "id": "dcfac30d07e302e6",
      "text": "NOTES\n- build a deep-learning neural net to build better deep-learning neural nets ??"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "AI Safety",
        "story": []
      },
      "date": 1519317150517
    },
    {
      "item": {
        "type": "factory",
        "id": "c5aaeabfc6ea0fd6"
      },
      "id": "c5aaeabfc6ea0fd6",
      "type": "add",
      "date": 1519317153393
    },
    {
      "type": "edit",
      "id": "c5aaeabfc6ea0fd6",
      "item": {
        "type": "markdown",
        "id": "c5aaeabfc6ea0fd6",
        "text": "AI Safety is, crudely, the concern that a true Artificial General Intelligence - one with an equivalent intelligence to a human, but with the additional technical nature of a machine (in other words, lacking the restrictions imposed by consisting of an organic 'whole'), could become superhuman in capacity, and that in this situation, it would be of critical importance that it be reliably 'friendly' to humans, and sufficiently aligned with human values that it would not make judgements about what it should do which would not be prejudicial to humans."
      },
      "date": 1519317413998
    },
    {
      "item": {
        "type": "factory",
        "id": "2b56ac3fad49737f"
      },
      "id": "2b56ac3fad49737f",
      "type": "add",
      "after": "c5aaeabfc6ea0fd6",
      "date": 1519317416183
    },
    {
      "type": "edit",
      "id": "2b56ac3fad49737f",
      "item": {
        "type": "markdown",
        "id": "2b56ac3fad49737f",
        "text": "This concern breaks down into a number of sub-topics:\n- the [[AI Alignment Problem]]\n- approaches to building [[Non-Superhuman AGI]] \n- approaches to building [[disinterested AGI]]"
      },
      "date": 1519317644493
    },
    {
      "item": {
        "type": "factory",
        "id": "e19c4c7e8c1919de"
      },
      "id": "e19c4c7e8c1919de",
      "type": "add",
      "after": "2b56ac3fad49737f",
      "date": 1519317655416
    },
    {
      "type": "edit",
      "id": "e19c4c7e8c1919de",
      "item": {
        "type": "markdown",
        "id": "e19c4c7e8c1919de",
        "text": "LINKS\n"
      },
      "date": 1519317678354
    },
    {
      "type": "edit",
      "id": "e19c4c7e8c1919de",
      "item": {
        "type": "markdown",
        "id": "e19c4c7e8c1919de",
        "text": "LINKS\n[Friendly AI through Ontology auto generation](https://medium.com/@pwgen/friendly-ai-through-ontology-autogeneration-5d375bf85922)"
      },
      "date": 1519317738378
    },
    {
      "type": "edit",
      "id": "e19c4c7e8c1919de",
      "item": {
        "type": "markdown",
        "id": "e19c4c7e8c1919de",
        "text": "LINKS\n[Friendly AI through Ontology auto generation](https://medium.com/@pwgen/friendly-ai-through-ontology-autogeneration-5d375bf85922)\n[Lesser Wrong AI Alignment prize](https://www.lesserwrong.com/posts/4WbNGQMvuFtY3So7s/announcement-ai-alignment-prize-winners-and-next-round)"
      },
      "date": 1519317820367
    },
    {
      "type": "edit",
      "id": "e19c4c7e8c1919de",
      "item": {
        "type": "markdown",
        "id": "e19c4c7e8c1919de",
        "text": "LINKS\n- [Friendly AI through Ontology auto generation](https://medium.com/@pwgen/friendly-ai-through-ontology-autogeneration-5d375bf85922)\n- [Lesser Wrong AI Alignment prize](https://www.lesserwrong.com/posts/4WbNGQMvuFtY3So7s/announcement-ai-alignment-prize-winners-and-next-round)"
      },
      "date": 1519317831357
    },
    {
      "item": {
        "type": "factory",
        "id": "dcfac30d07e302e6"
      },
      "id": "dcfac30d07e302e6",
      "type": "add",
      "after": "e19c4c7e8c1919de",
      "date": 1519318324135
    },
    {
      "type": "edit",
      "id": "dcfac30d07e302e6",
      "item": {
        "type": "markdown",
        "id": "dcfac30d07e302e6",
        "text": "NOTES\n- "
      },
      "date": 1519318345454
    },
    {
      "type": "edit",
      "id": "dcfac30d07e302e6",
      "item": {
        "type": "markdown",
        "id": "dcfac30d07e302e6",
        "text": "NOTES\n- build a deep-learning neural net to build better deep-learning neural nets ??"
      },
      "date": 1519318412944
    }
  ]
}