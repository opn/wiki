{
  "title": "Is Faireness A Bug?",
  "story": [
    {
      "type": "paragraph",
      "id": "bef43ee159095fdc",
      "text": "The title may not make sense, but it's catchy. Here we look at the issue od [[Decidability]] and human action - which may be a better title."
    },
    {
      "type": "markdown",
      "id": "77e5268121a700f9",
      "text": "# Intent is fundamentally complex."
    },
    {
      "type": "pagefold",
      "id": "66ae4fbe1f91d6bf",
      "text": "Vitalik Buterin"
    },
    {
      "type": "paragraph",
      "id": "43d35f60da1ae47c",
      "text": "The philosophy behind this fact has been best formalized by the friendly AI research community, where is bears the names of “complexity of value” and “fragility of value“. "
    },
    {
      "type": "paragraph",
      "id": "d0418440a7feff48",
      "text": "The thesis is simple: we as human beings have very many values, and very complex values – so complex that we ourselves are not capable of fully expressing them, and any attempt to will inevitably contain some uncovered corner case. "
    },
    {
      "type": "paragraph",
      "id": "920e36ffb254651e",
      "text": "The utility of the concept to AI research is important because a super-intelligent AI would in fact search through every corner, including corners that we find so unintuitive that we do not even think of them, to maximize its objective. "
    },
    {
      "type": "paragraph",
      "id": "6f348bc5c29b568b",
      "text": "Tell a superintelligent AI to cure cancer, and it will get 99.99% of the way there through some moderately complex tweaks in molecular biology, but it will soon realize that it can bump that up to 100% by triggering human extinction through a nuclear war and/or biological pandemic. "
    },
    {
      "type": "paragraph",
      "id": "6dae07dd0b57ffa7",
      "text": "Tell it to cure cancer without killing humans, and it will simply force all humans to freeze themselves, reasoning that it’s not technically killing because it could wake the humans up if it wanted to – it just won’t. And so forth."
    },
    {
      "type": "paragraph",
      "id": "643c2a2aa9e7ffeb",
      "text": "In smart contract land, the situation is similar. We believe that we value things like “fairness”, but it’s hard to define what fairness even means. "
    },
    {
      "type": "paragraph",
      "id": "93209b740809bdcb",
      "text": "You may want to say things like “it should not be possible for someone to just steal 10000 ETH from a DAO”, but what if, for a given withdrawal transaction, the DAO actually approved of the transfer because the recipient provided a valuable service? "
    },
    {
      "type": "paragraph",
      "id": "defb11dc6a2244b6",
      "text": "But then, if the transfer was approved, how do we know that the mechanism for deciding this wasn’t fooled through a game-theoretic vulnerability? What is a game-theoretic vulnerability? "
    },
    {
      "type": "paragraph",
      "id": "6208324ad3b7297f",
      "text": "What about “splitting”? In the case of a blockchain-based market, what about front-running? If a given contract specifies an “owner” who can collect fees, what if the ability for anyone to become the owner was actually part of the rules, to add to the fun?"
    },
    {
      "type": "paragraph",
      "id": "30705aab78d0c79c",
      "text": "All of this is not a strike against experts in formal verification, type theory, weird programming languages and the like; the smart ones already know and appreciate these issues. "
    },
    {
      "type": "paragraph",
      "id": "eb2cb691e53bd34a",
      "text": "However, it does show that there is a fundamental barrier to what can be accomplished, and “fairness” is not something that can be mathematically proven in a theorem – in some cases, the set of fairness claims is so long and complex that you have to wonder if the set of claims itself might have a bug - [https://blog.ethereum.org/2016/06/19/thinking-smart-contract-security/ blog.ethereum.org]"
    },
    {
      "type": "pagefold",
      "id": "2500aa2177059638",
      "text": "."
    },
    {
      "type": "markdown",
      "id": "d573fdc61f2e1702",
      "text": "# See also\n\n* Intuitionistic logic  - [https://en.wikipedia.org/wiki/Intuitionistic_logic wikipedia]\n* [[Dumb Contracts]]"
    }
  ],
  "journal": [
    {
      "type": "create",
      "item": {
        "title": "Is Faireness A Bug?",
        "story": []
      },
      "date": 1466347599601
    },
    {
      "item": {
        "type": "factory",
        "id": "77e5268121a700f9"
      },
      "id": "77e5268121a700f9",
      "type": "add",
      "date": 1466347600955
    },
    {
      "type": "edit",
      "id": "77e5268121a700f9",
      "item": {
        "type": "paragraph",
        "id": "77e5268121a700f9",
        "text": "# Intent is fundamentally complex."
      },
      "date": 1466347616938
    },
    {
      "type": "add",
      "id": "43d35f60da1ae47c",
      "item": {
        "type": "paragraph",
        "id": "43d35f60da1ae47c",
        "text": "The philosophy behind this fact has been best formalized by the friendly AI research community, where is bears the names of “complexity of value” and “fragility of value“. "
      },
      "after": "77e5268121a700f9",
      "date": 1466347635308
    },
    {
      "type": "add",
      "id": "d0418440a7feff48",
      "item": {
        "type": "paragraph",
        "id": "d0418440a7feff48",
        "text": "The thesis is simple: we as human beings have very many values, and very complex values – so complex that we ourselves are not capable of fully expressing them, and any attempt to will inevitably contain some uncovered corner case. "
      },
      "after": "43d35f60da1ae47c",
      "date": 1466347642510
    },
    {
      "type": "add",
      "id": "920e36ffb254651e",
      "item": {
        "type": "paragraph",
        "id": "920e36ffb254651e",
        "text": "The utility of the concept to AI research is important because a super-intelligent AI would in fact search through every corner, including corners that we find so unintuitive that we do not even think of them, to maximize its objective. "
      },
      "after": "d0418440a7feff48",
      "date": 1466347648732
    },
    {
      "type": "add",
      "id": "6f348bc5c29b568b",
      "item": {
        "type": "paragraph",
        "id": "6f348bc5c29b568b",
        "text": "Tell a superintelligent AI to cure cancer, and it will get 99.99% of the way there through some moderately complex tweaks in molecular biology, but it will soon realize that it can bump that up to 100% by triggering human extinction through a nuclear war and/or biological pandemic. "
      },
      "after": "920e36ffb254651e",
      "date": 1466347666806
    },
    {
      "type": "add",
      "id": "6dae07dd0b57ffa7",
      "item": {
        "type": "paragraph",
        "id": "6dae07dd0b57ffa7",
        "text": "Tell it to cure cancer without killing humans, and it will simply force all humans to freeze themselves, reasoning that it’s not technically killing because it could wake the humans up if it wanted to – it just won’t. And so forth."
      },
      "after": "6f348bc5c29b568b",
      "date": 1466347668685
    },
    {
      "type": "add",
      "id": "643c2a2aa9e7ffeb",
      "item": {
        "type": "paragraph",
        "id": "643c2a2aa9e7ffeb",
        "text": "In smart contract land, the situation is similar. We believe that we value things like “fairness”, but it’s hard to define what fairness even means. "
      },
      "after": "6dae07dd0b57ffa7",
      "date": 1466347677079
    },
    {
      "type": "add",
      "id": "93209b740809bdcb",
      "item": {
        "type": "paragraph",
        "id": "93209b740809bdcb",
        "text": "You may want to say things like “it should not be possible for someone to just steal 10000 ETH from a DAO”, but what if, for a given withdrawal transaction, the DAO actually approved of the transfer because the recipient provided a valuable service? "
      },
      "after": "643c2a2aa9e7ffeb",
      "date": 1466347689943
    },
    {
      "type": "add",
      "id": "defb11dc6a2244b6",
      "item": {
        "type": "paragraph",
        "id": "defb11dc6a2244b6",
        "text": "But then, if the transfer was approved, how do we know that the mechanism for deciding this wasn’t fooled through a game-theoretic vulnerability? What is a game-theoretic vulnerability? "
      },
      "after": "93209b740809bdcb",
      "date": 1466347693752
    },
    {
      "type": "add",
      "id": "6208324ad3b7297f",
      "item": {
        "type": "paragraph",
        "id": "6208324ad3b7297f",
        "text": "What about “splitting”? In the case of a blockchain-based market, what about front-running? If a given contract specifies an “owner” who can collect fees, what if the ability for anyone to become the owner was actually part of the rules, to add to the fun?"
      },
      "after": "defb11dc6a2244b6",
      "date": 1466347698848
    },
    {
      "item": {
        "type": "factory",
        "id": "2500aa2177059638"
      },
      "id": "2500aa2177059638",
      "type": "add",
      "after": "6208324ad3b7297f",
      "date": 1466347703514
    },
    {
      "type": "edit",
      "id": "2500aa2177059638",
      "item": {
        "type": "pagefold",
        "id": "2500aa2177059638",
        "text": "."
      },
      "date": 1466347708817
    },
    {
      "item": {
        "type": "factory",
        "id": "66ae4fbe1f91d6bf"
      },
      "id": "66ae4fbe1f91d6bf",
      "type": "add",
      "after": "2500aa2177059638",
      "date": 1466347710188
    },
    {
      "type": "move",
      "order": [
        "77e5268121a700f9",
        "43d35f60da1ae47c",
        "66ae4fbe1f91d6bf",
        "d0418440a7feff48",
        "920e36ffb254651e",
        "6f348bc5c29b568b",
        "6dae07dd0b57ffa7",
        "643c2a2aa9e7ffeb",
        "93209b740809bdcb",
        "defb11dc6a2244b6",
        "6208324ad3b7297f",
        "2500aa2177059638"
      ],
      "id": "66ae4fbe1f91d6bf",
      "date": 1466347717238
    },
    {
      "type": "move",
      "order": [
        "77e5268121a700f9",
        "66ae4fbe1f91d6bf",
        "43d35f60da1ae47c",
        "d0418440a7feff48",
        "920e36ffb254651e",
        "6f348bc5c29b568b",
        "6dae07dd0b57ffa7",
        "643c2a2aa9e7ffeb",
        "93209b740809bdcb",
        "defb11dc6a2244b6",
        "6208324ad3b7297f",
        "2500aa2177059638"
      ],
      "id": "43d35f60da1ae47c",
      "date": 1466347720168
    },
    {
      "type": "edit",
      "id": "66ae4fbe1f91d6bf",
      "item": {
        "type": "pagefold",
        "id": "66ae4fbe1f91d6bf",
        "text": "Vitalik Buterin"
      },
      "date": 1466347752266
    },
    {
      "type": "edit",
      "id": "77e5268121a700f9",
      "item": {
        "type": "markdown",
        "id": "77e5268121a700f9",
        "text": "# Intent is fundamentally complex."
      },
      "date": 1466347756656
    },
    {
      "item": {
        "type": "factory",
        "id": "bef43ee159095fdc"
      },
      "id": "bef43ee159095fdc",
      "type": "add",
      "after": "2500aa2177059638",
      "date": 1466347759244
    },
    {
      "type": "move",
      "order": [
        "bef43ee159095fdc",
        "77e5268121a700f9",
        "66ae4fbe1f91d6bf",
        "43d35f60da1ae47c",
        "d0418440a7feff48",
        "920e36ffb254651e",
        "6f348bc5c29b568b",
        "6dae07dd0b57ffa7",
        "643c2a2aa9e7ffeb",
        "93209b740809bdcb",
        "defb11dc6a2244b6",
        "6208324ad3b7297f",
        "2500aa2177059638"
      ],
      "id": "bef43ee159095fdc",
      "date": 1466347761454
    },
    {
      "type": "edit",
      "id": "bef43ee159095fdc",
      "item": {
        "type": "paragraph",
        "id": "bef43ee159095fdc",
        "text": "The title may not make sense, but it's catchy. Here we look at the issue od [[Decidability]] and human action - which may be a better title."
      },
      "date": 1466347827117
    },
    {
      "item": {
        "type": "factory",
        "id": "d573fdc61f2e1702"
      },
      "id": "d573fdc61f2e1702",
      "type": "add",
      "after": "2500aa2177059638",
      "date": 1466349784359
    },
    {
      "type": "edit",
      "id": "d573fdc61f2e1702",
      "item": {
        "type": "markdown",
        "id": "d573fdc61f2e1702",
        "text": "# See also\n\n* Intuitionistic logic  - [https://en.wikipedia.org/wiki/Intuitionistic_logic wikipedia]"
      },
      "date": 1466349825739
    },
    {
      "type": "add",
      "id": "30705aab78d0c79c",
      "item": {
        "type": "paragraph",
        "id": "30705aab78d0c79c",
        "text": "All of this is not a strike against experts in formal verification, type theory, weird programming languages and the like; the smart ones already know and appreciate these issues. "
      },
      "after": "6208324ad3b7297f",
      "date": 1466349877538
    },
    {
      "type": "add",
      "id": "eb2cb691e53bd34a",
      "item": {
        "type": "paragraph",
        "id": "eb2cb691e53bd34a",
        "text": "However, it does show that there is a fundamental barrier to what can be accomplished, and “fairness” is not something that can be mathematically proven in a theorem – in some cases, the set of fairness claims is so long and complex that you have to wonder if the set of claims itself might have a bug."
      },
      "after": "30705aab78d0c79c",
      "date": 1466349886229
    },
    {
      "type": "edit",
      "id": "eb2cb691e53bd34a",
      "item": {
        "type": "paragraph",
        "id": "eb2cb691e53bd34a",
        "text": "However, it does show that there is a fundamental barrier to what can be accomplished, and “fairness” is not something that can be mathematically proven in a theorem – in some cases, the set of fairness claims is so long and complex that you have to wonder if the set of claims itself might have a bug - [https://blog.ethereum.org/2016/06/19/thinking-smart-contract-security/ blog.ethereum.org]"
      },
      "date": 1466350289488
    },
    {
      "type": "fork",
      "site": "wiki.parliamentofthings.org",
      "date": 1466350526747
    },
    {
      "type": "edit",
      "id": "d573fdc61f2e1702",
      "item": {
        "type": "markdown",
        "id": "d573fdc61f2e1702",
        "text": "# See also\n\n* Intuitionistic logic  - [https://en.wikipedia.org/wiki/Intuitionistic_logic wikipedia]\n* [[Dumb Contracts]]"
      },
      "date": 1466352446251
    }
  ]
}